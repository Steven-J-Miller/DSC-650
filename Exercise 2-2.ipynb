{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Steven Miller**\n",
    "### DSC 650 Winter 2019\n",
    "### 2019-12-04\n",
    "#### 2.2 Programming Exercise: Setup Spark, Load Data, and Work with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('Exercise').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Load Data and Show Schema\n",
    "\n",
    "Load the baby-names.csv file into Spark dataframe as a text file. Print the dataframe’s schema using the printSchema method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baby_names_text = spark.read.text('baby-names/baby-names.csv')\n",
    "baby_names_text.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Filtering and Counting\n",
    "\n",
    "First, count the number of rows in the dataframe. Second, filter the dataframe so that it only contains rows that contain John. Count the number of rows in the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file has 5933562 rows.\n",
      "This file has 21785 rows that contain John.\n"
     ]
    }
   ],
   "source": [
    "print(f'This file has {baby_names_text.count()} rows.')\n",
    "johns_text = baby_names_text.filter(baby_names_text.value.contains(\"John\"))\n",
    "print(f'This file has {johns_text.count()} rows that contain John.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Working with DataFrames\n",
    "\n",
    "In the previous part of the exercise, you loaded the data into the dataframe as a text file. As a consequence, Spark treated each line as a record with a single field. While this is useful for some applications (processing raw text), it is not useful when our original data contains structure. In this part of the exercise, load baby-names.csv as a CSV file instead of a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Load Data and Show Schema\n",
    "\n",
    "Load the baby-names.csv file as a CSV file instead of a text file. Print the schema for this dataframe. In addition to printing the dataframe’s schema, show the first 20 rows of data using the show method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n",
      "+-----+---+----+---------+-----+\n",
      "|state|sex|year|     name|count|\n",
      "+-----+---+----+---------+-----+\n",
      "|   AK|  F|1910|     Mary|   14|\n",
      "|   AK|  F|1910|    Annie|   12|\n",
      "|   AK|  F|1910|     Anna|   10|\n",
      "|   AK|  F|1910| Margaret|    8|\n",
      "|   AK|  F|1910|    Helen|    7|\n",
      "|   AK|  F|1910|    Elsie|    6|\n",
      "|   AK|  F|1910|     Lucy|    6|\n",
      "|   AK|  F|1910|  Dorothy|    5|\n",
      "|   AK|  F|1911|     Mary|   12|\n",
      "|   AK|  F|1911| Margaret|    7|\n",
      "|   AK|  F|1911|     Ruth|    7|\n",
      "|   AK|  F|1911|    Annie|    6|\n",
      "|   AK|  F|1911|Elizabeth|    6|\n",
      "|   AK|  F|1911|    Helen|    6|\n",
      "|   AK|  F|1912|     Mary|    9|\n",
      "|   AK|  F|1912|    Elsie|    8|\n",
      "|   AK|  F|1912|    Agnes|    7|\n",
      "|   AK|  F|1912|     Anna|    7|\n",
      "|   AK|  F|1912|    Helen|    7|\n",
      "|   AK|  F|1912|   Louise|    7|\n",
      "+-----+---+----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baby_names_df = spark.read.csv('baby-names/baby-names.csv', header=True, inferSchema=True)\n",
    "baby_names_df.printSchema()\n",
    "baby_names_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Filtering and Counting\n",
    "\n",
    "Filter the dataframe so that it only contains rows that contain the name John. Count the number of rows in the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe has 21785 rows that contain John.\n"
     ]
    }
   ],
   "source": [
    "df_Johns = baby_names_df.where(baby_names_df.name.contains(\"John\"))\n",
    "print(f'This dataframe has {df_Johns.count()} rows that contain John.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Sorting and Limits\n",
    "\n",
    "For this step, filter the dataframe to include only males (sex=‘M’) born in Nebraska (state=‘NE’) in 1980 (year=‘1980’). Sort the dataframe by descending values of count and show the first ten rows. The result should be the top ten most popular boy’s names for 1980 in Nebraska.\n",
    "\n",
    "Make sure that you save files that are output from each task, as they may be needed for other tasks. These include prepared corpus, trained models, and reports.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Nebraska_Males_1980 = baby_names_df.where((baby_names_df.state == 'NE') & (baby_names_df.sex == 'M') & (baby_names_df.year == '1980'))\n",
    "df_Nebraska_Males_1980 = df_Nebraska_Males_1980.orderBy(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+-----------+-----+\n",
      "|state|sex|year|       name|count|\n",
      "+-----+---+----+-----------+-----+\n",
      "|   NE|  M|1980|    Matthew|  434|\n",
      "|   NE|  M|1980|    Michael|  426|\n",
      "|   NE|  M|1980|      Jason|  409|\n",
      "|   NE|  M|1980|     Joshua|  366|\n",
      "|   NE|  M|1980|Christopher|  359|\n",
      "|   NE|  M|1980|     Justin|  337|\n",
      "|   NE|  M|1980|       Ryan|  320|\n",
      "|   NE|  M|1980|      David|  292|\n",
      "|   NE|  M|1980|     Andrew|  281|\n",
      "|   NE|  M|1980|      Brian|  278|\n",
      "|   NE|  M|1980|   Nicholas|  258|\n",
      "|   NE|  M|1980|       John|  258|\n",
      "|   NE|  M|1980|     Jeremy|  241|\n",
      "|   NE|  M|1980|      James|  238|\n",
      "|   NE|  M|1980|     Joseph|  212|\n",
      "|   NE|  M|1980|       Adam|  209|\n",
      "|   NE|  M|1980|     Daniel|  209|\n",
      "|   NE|  M|1980|       Eric|  205|\n",
      "|   NE|  M|1980|    Timothy|  188|\n",
      "|   NE|  M|1980|     Robert|  187|\n",
      "+-----+---+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Nebraska_Males_1980.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
